{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6b5mX1DE1pAoWlnB1/v61",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erick1439/CAP4630-Wocjan/blob/master/HW_5/HW_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HADODPXyGhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mpl_toolkits import mplot3d\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI_dNAtCg2yW",
        "colab_type": "text"
      },
      "source": [
        "# **Description:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKCW6aAEg0Cy",
        "colab_type": "text"
      },
      "source": [
        "Summarize and describe the different concepts/methods/algorithms that you have learned in this course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAGJqsZVg-Hf",
        "colab_type": "text"
      },
      "source": [
        "# **Summary:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U91XjtrxiB3_",
        "colab_type": "text"
      },
      "source": [
        "## **General Concepts:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i1L3iaYEkYY",
        "colab_type": "text"
      },
      "source": [
        "### ***Artificial Intelligence:*** \n",
        "\n",
        "I learned that AI is an umbrella term used to represents a branch of computer science dealing with the simulation of intelligent behavior in computers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ7waO8SFyQT",
        "colab_type": "text"
      },
      "source": [
        "### ***Symobolic AI:***\n",
        "This is a term used to represent the collection of all methods in AI research that are based on high-level representations of problems. This term is also known as \"good old-fashioned Artificial Intelligence\" or GOFAI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzQr89XvHpkd",
        "colab_type": "text"
      },
      "source": [
        "### ***Machine Learning:***\n",
        "\n",
        "I learned that this term is a subset of AI which is used to represent the field of study that gives computers the ability to learn without being explicitly programmed. This means that Machine Learning is the process of training a model to make useful predictions using a data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzdoefxBKNVF",
        "colab_type": "text"
      },
      "source": [
        "#### ***Supervised Learning:***\n",
        "I learned that this is a paradigm from ML where a model will receive a label and training data. In the learning section, the model will do calculations to find patterns and relationships between the data and labels so when the model sees new data it can make close predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm7uNqx_N1X3",
        "colab_type": "text"
      },
      "source": [
        "#### ***Unsupervised Learning:***\n",
        "In this type of learning the model will have only unlabeled data. This means that the model will have no hints on how to categorize data. This type of learning is more useful if we want to classify new data in already existing clusters of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTgRBPUlPPJl",
        "colab_type": "text"
      },
      "source": [
        "#### ***Reinforcement Learning:***\n",
        "I learned that on this type of learning you do not collect examples with the label. Instead, we have an agent that will learn how to interact with an environment through trial and error using feedback from previous actions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiCwXpeaUttA",
        "colab_type": "text"
      },
      "source": [
        "### **Deep Learning:**\n",
        "Deep learning is a set of machine learning based on artificial neural networks. The learning can be supervised or unsupervised."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I4D3D3tVTng",
        "colab_type": "text"
      },
      "source": [
        "## **Basic Concepts:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LahJFUFFVcva",
        "colab_type": "text"
      },
      "source": [
        "### **Linear Regression:**\n",
        "Linear regression is a formula that attempts to model a relationship between variables. In the most basic example, it will create a line where it maps a dependent variable to an independent variable. The linear regression equation could be written as : $\\hat y = mx + b$, but for this course the formula $\\hat y = b + \\sum_{j = 1}^n W_j X_j$ makes a better representation since it represents the linear regression with multiple features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhWQWdbV9sW-",
        "colab_type": "code",
        "outputId": "67f17f9b-affa-470c-a6d2-99b02340dc5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Display data points on the graph\n",
        "rng = np.random.RandomState(1)\n",
        "x = 10 * rng.rand(50)\n",
        "y = 2 * x - 5 + rng.randn(50)\n",
        "plt.scatter(x, y);\n",
        "\n",
        "# Generates the linear regression line\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(x[:, np.newaxis], y)\n",
        "xfit = np.linspace(0, 10, 1000)\n",
        "yfit = model.predict(xfit[:, np.newaxis])\n",
        "\n",
        "# Displays the line on the graph\n",
        "plt.scatter(x, y)\n",
        "plt.plot(xfit, yfit);"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU6FnaYTZno3",
        "colab_type": "text"
      },
      "source": [
        "### **Mean Square Error Loss:**\n",
        "Loss defines the penalty for a bad prediction from a single weight. Mean square error refers to the average squared loss per example over the whole dataset. The MSE can be represented as: $ \\frac{1}{m} \\sum_{i = 1}^m (y^i - \\hat y^i)^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKGHeeJ7JdK6",
        "colab_type": "text"
      },
      "source": [
        "### Binary crossentropy:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFGz4IfEJq9W",
        "colab_type": "text"
      },
      "source": [
        "Binary cross-entropy is another type of loss function used primarily with logistic regression. Binary cross-entropy will measure how far away from a true value a prediction will be measuring the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJAUaTSwJkEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_cross_entropy_loss(a, label):\n",
        "    return (-label * np.log(a)) - ((1 - label) * np.log(1 - a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvrNVJMRYdhT",
        "colab_type": "text"
      },
      "source": [
        "### **Logistic Regression:**\n",
        "This is a supervised learning algorithm that allows us to predict if something is true or false. Instead of having predictions for continuous values like in linear regression, we will use logistic regression to classify data into two categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGVzTt-DYoNZ",
        "colab_type": "text"
      },
      "source": [
        "### **Gradients:**\n",
        "Gradients are vectors containing derivatives of functions with respect to all of its variables. One of the uses of gradients is to find the steepest ascent for a function at a given point.\n",
        "\n",
        "Below is an expalme of the gradient descent ot the function cos(x) + sin(y) at the point $(0, - \\frac{\\pi}{2})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFTFXWD8xU7P",
        "colab_type": "code",
        "outputId": "cde38c7f-e338-498c-fdf8-6d59951edb89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "def f3(x, y):\n",
        "  return np.cos(x) + np.sin(y)\n",
        "\n",
        "x = np.linspace(-4, 4, 30)\n",
        "y = np.linspace(-4, 4, 30)\n",
        "\n",
        "X, Y = np.meshgrid(x, y)\n",
        "Z = f3(X, Y)\n",
        "\n",
        "plt.contourf(X, Y, Z, 20, cmap='RdGy')\n",
        "plt.colorbar()\n",
        "plt.plot(0, -np.pi / 2, 'o', c='green')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EolPuNIUZ2It",
        "colab_type": "text"
      },
      "source": [
        "### **Gradient Descent:**\n",
        "This a technique we use to minimize the error loss of a model by adjusting its weights. This optimization technique works by iteratively moving in the direction of the functions' steepest descent. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U4cxeGGZ6Ju",
        "colab_type": "text"
      },
      "source": [
        "### **Stochastic/ Mini Batch Gradient Descent:**\n",
        "Stochastic and Mini batch are two modifications of gradient descent. Running the gradient descent algorithm can be very costly because of the many math computations the algorithm will have to compute with big sets of data. To prevent this we can use Stochastic and mini-batch gradient descent. Sotachistic will randomly select an element from the training set at each step. In the other side, the mini-batch will use a small collection of randomly chosen elements from the training set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNDvi9Hq1deI",
        "colab_type": "text"
      },
      "source": [
        "## **Building a Model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJshcTwlLsp2",
        "colab_type": "text"
      },
      "source": [
        "Keras allows us to build neural networks in a condense way. In the lines below we are creating a sequential model that will organize out the layer in stack looking fashion. After that, we are inserting a dense layer to the model that will use a sigmoid activation. The sigmoid argument will make sure that our output is between the interval 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMhWfeEoLy93",
        "colab_type": "code",
        "outputId": "1a948c7d-4ff6-43a6-c7c1-cecb14696cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Creates the model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Adds dense layer to the model\n",
        "layer = tf.keras.layers.Dense(1, activation='sigmoid', input_shape=(2, ))\n",
        "model.add(layer)\n",
        "\n",
        "# Summary\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYMcWMcg1CjU",
        "colab_type": "text"
      },
      "source": [
        "### **Types of layers:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73cVJ8MU1Npi",
        "colab_type": "text"
      },
      "source": [
        "There are different types of layers that Keras offer. The dense layer used above is just one of the many. Below are just some layers we have come across:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqtBkvG71hBD",
        "colab_type": "text"
      },
      "source": [
        "#### **Dense:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31qi8VCT15d4",
        "colab_type": "text"
      },
      "source": [
        "Dense is one of the most basic types of layers. This layer uses the gradiant descent technique to adjust the features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaaXaKKC1wfC",
        "colab_type": "text"
      },
      "source": [
        "#### **Flatten:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K3nwHr_Boa1",
        "colab_type": "text"
      },
      "source": [
        "The flatten layer can take an input of multiple dimensions and flatten that into a 1d array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1yO0buy1k4W",
        "colab_type": "text"
      },
      "source": [
        "#### **Conv2D:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itDcd4WX4bAc",
        "colab_type": "text"
      },
      "source": [
        "This layer works by receiving an input matrix and a kernel. Then this kernel will be used to multiply the input matrix on a specific region of the input matrix and then add its products. This process will continue until all the input matrix positions have been processed. The code below is the example from hw4 that computes the conv2d on squares matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJyH_SlS1rOz",
        "colab_type": "code",
        "outputId": "9bf1a36e-1cd9-4ea6-d05b-6bd59f2a2673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def conv2d(input_mat, kernel_mat):\n",
        "    # Special cases in order to avoid errors on the computation.\n",
        "\n",
        "    if kernel_mat.shape[0] != kernel_mat.shape[1]:\n",
        "      return \"Kernel matrix is not square\"\n",
        "    \n",
        "    if input_mat.shape[0] != input_mat.shape[1]:\n",
        "      return \"Input matrix is not square\"\n",
        "\n",
        "    if kernel_mat.shape[0] > input_mat.shape[0]:\n",
        "      return \"Kernel size is greater than the input size\"\n",
        "\n",
        "    # Statements that calculate the new length of the result matrix.\n",
        "    result_mat = np.zeros((input_mat.shape[0] - kernel_mat.shape[0] + 1, input_mat.shape[0] - kernel_mat.shape[0] + 1))\n",
        "\n",
        "    # Loops that calculate the convolution computations\n",
        "    for col in range(result_mat.shape[0]):\n",
        "        for row in range(result_mat.shape[1]):\n",
        "          x_bound = row + kernel_mat.shape[0];\n",
        "          y_bound = col + kernel_mat.shape[0]\n",
        "          temp_mat = np.multiply(input_mat[col:y_bound, row:x_bound], kernel_mat)\n",
        "          result_mat[col][row] = np.sum(temp_mat)\n",
        "\n",
        "    return result_mat\n",
        "\n",
        "\n",
        "# Test case : \n",
        "input_mat = np.array([[1, 2, 3],\n",
        "                      [1, 2, 3],\n",
        "                      [1, 2, 3]])\n",
        "\n",
        "kernel_mat = np.array([[1, 1],\n",
        "                       [1, 1]])\n",
        "\n",
        "print(conv2d(input_mat, kernel_mat), end=\"\\n\\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6. 10.]\n",
            " [ 6. 10.]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4SXgTIJ1rsc",
        "colab_type": "text"
      },
      "source": [
        "#### **MaxPooling2D:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWE6Qnsf8GH7",
        "colab_type": "text"
      },
      "source": [
        "This layer works get the max number from a region specified by a value passed as another parameter. This technique will also stop when all the values of the input matrix have been processed. The example below is from hw4 that works only with only square matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_TP2S9E7S1Y",
        "colab_type": "code",
        "outputId": "38c3a883-c52a-44a5-9233-25dd60cbf83a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def maxpooling2d(input_mat, s):\n",
        "\n",
        "  # Special cases in order to avoid errors on the computation.\n",
        "  if input_mat.shape[0] != input_mat.shape[1]:\n",
        "    return \"Input Matrix is not square\"\n",
        "\n",
        "  if s <= 0:\n",
        "    return \"Make sure the value in s is valid\"\n",
        "\n",
        "  if s > input_mat.shape[0]:\n",
        "    return \"The value in s is largert the input size\"\n",
        "\n",
        "  # Statements that calculate the new length of the result matrix.\n",
        "  result_mat = np.zeros((input_mat.shape[0] // s, input_mat.shape[0] // s))\n",
        "\n",
        "  # Perform the max pooling operation\n",
        "  for col in range(result_mat.shape[0]):\n",
        "    for row in range(result_mat.shape[0]):\n",
        "      x_bound = row * s\n",
        "      y_bound = col * s\n",
        "      result_mat[col][row] = np.amax(input_mat[y_bound:y_bound + s, x_bound:x_bound + s])\n",
        "\n",
        "  return result_mat\n",
        "\n",
        "\n",
        "# Test case:\n",
        "input_mat = np.array([[1, 2, 3, 4],\n",
        "                      [5, 6, 7, 8],\n",
        "                      [9, 10, 11, 12],\n",
        "                      [13, 14, 15, 16]])\n",
        "\n",
        "print(maxpooling2d(input_mat, 2), end=\"\\n\\n\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6.  8.]\n",
            " [14. 16.]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzavZlaR16fl",
        "colab_type": "text"
      },
      "source": [
        "## **Comping a Model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74l21jehuKGZ",
        "colab_type": "text"
      },
      "source": [
        "The model above can be compiled with the line below. The optimizer parameter is in charge to set how the data is going to be updated at each iteration. The loss parameter is in charge to set the algorithm that will be used to calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s7GJnjj5d57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEJjpvSX2E06",
        "colab_type": "text"
      },
      "source": [
        "## **Training a Model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcKcyHwR5KM4",
        "colab_type": "text"
      },
      "source": [
        "#### ***Overfitting:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjIt1n_9Z6kE",
        "colab_type": "text"
      },
      "source": [
        "Overfitting is a pitfall where a model will train training-data too well. This is bad because it will cause a big loss in unseen data. This usually happens when the model learns the noise and the detailed rules for the training. One of the ways to avoid this problem is by using more general rules to train the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGI6zDlQ5bd-",
        "colab_type": "text"
      },
      "source": [
        "#### ***Underfitting:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aes4vLLHeFSq",
        "colab_type": "text"
      },
      "source": [
        "Underfitting refers to a model that can not train data or generalize new data. To fix this, we can change the learning rate or increase the amount of training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU_1eR8nLG5F",
        "colab_type": "text"
      },
      "source": [
        "#### **Training model Example:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zDVQ6uLLdcC",
        "colab_type": "text"
      },
      "source": [
        "The example below is part of hw3 that implements logistic regression with two features and training data from the get_random() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlurMwdIJm6V",
        "colab_type": "code",
        "outputId": "09a7a35a-4a55-41b1-ff45-a3ff09baccfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def get_random_data(w, b, mu, sigma, m):\n",
        "  # Generates array with ones and zeros.\n",
        "  labels = np.random.choice([0, 1], size=(m,1))\n",
        "  \n",
        "  # Generates uniformly random data.\n",
        "  X_1 = np.random.uniform(0, 1, size=(m, 1))\n",
        "\n",
        "  # Generates random data with mean distribution of mu, and sd of sigma.\n",
        "  N = np.random.normal(mu, sigma, size=(m, 1))\n",
        "\n",
        "  # Sets the second feature\n",
        "  X_2 = w * X_1 + b + (-1)**labels * N\n",
        "\n",
        "  # Concatenates the features X_1 & X_2 to produce the array with a shape of (m, 2).\n",
        "  data = np.concatenate((X_1, X_2), axis=1)\n",
        "\n",
        "  return data, labels\n",
        "\n",
        "def split_data(data, labels):\n",
        "  # Splits the data with a 80:20 ratio\n",
        "  train_data = data[:(int)(m * 0.8)]\n",
        "  test_data = data[(int)(m * 0.8):]\n",
        "  train_labels = labels[:(int)(m * 0.8)]\n",
        "  test_labels = labels[(int)(m * 0.8):]\n",
        "\n",
        "  return train_data, test_data, train_labels, test_labels\n",
        "\n",
        "def display_random_data (data, labels, w, b):\n",
        "  # Display data points \n",
        "  pt = labels.flatten()\n",
        "  temp1 = data[pt == 0,:]\n",
        "  temp2 = data[pt == 1,:]\n",
        "  plt.scatter(temp1[:,0], temp1[:,1], c='blue', label='X_1')\n",
        "  plt.scatter(temp2[:,0], temp2[:,1], c='red', label='X_2')\n",
        "\n",
        "  # Displays line that splits the data\n",
        "  slope = np.linspace(0, 1)\n",
        "  y = w * slope + b\n",
        "  plt.plot(slope, y, 'black')\n",
        "\n",
        "  # Labels the graph\n",
        "  plt.title('Data Distribution')\n",
        "  plt.xlabel('$Y$')\n",
        "  plt.ylabel('$X$')\n",
        "\n",
        "\n",
        "w = 2\n",
        "b = 7\n",
        "mu = 4\n",
        "sigma = 1.5\n",
        "m = 1000\n",
        "\n",
        "data, labels = get_random_data(w, b, mu, sigma, m)\n",
        "train_data, test_data, train_labels, test_labels = split_data(data, labels)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 40\n",
        "\n",
        "# Creates the model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Adds dense layer to the model\n",
        "layer = tf.keras.layers.Dense(1, activation='sigmoid', input_shape=(2, ))\n",
        "model.add(layer)\n",
        "\n",
        "# Compiles the model\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Trains the model\n",
        "model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(test_data, test_labels))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6860 - accuracy: 0.4950 - val_loss: 0.6501 - val_accuracy: 0.5200\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.5450 - val_loss: 0.5838 - val_accuracy: 0.5750\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.6087 - val_loss: 0.5284 - val_accuracy: 0.6100\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.6875 - val_loss: 0.4772 - val_accuracy: 0.7500\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7912 - val_loss: 0.4314 - val_accuracy: 0.8400\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4202 - accuracy: 0.8562 - val_loss: 0.3884 - val_accuracy: 0.9200\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8975 - val_loss: 0.3542 - val_accuracy: 0.9750\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.9388 - val_loss: 0.3160 - val_accuracy: 0.9750\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.9550 - val_loss: 0.2887 - val_accuracy: 0.9750\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2845 - accuracy: 0.9688 - val_loss: 0.2570 - val_accuracy: 0.9750\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2597 - accuracy: 0.9750 - val_loss: 0.2336 - val_accuracy: 0.9750\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9812 - val_loss: 0.2149 - val_accuracy: 0.9750\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.9875 - val_loss: 0.1938 - val_accuracy: 0.9750\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9900 - val_loss: 0.1770 - val_accuracy: 0.9750\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.9887 - val_loss: 0.1628 - val_accuracy: 0.9750\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9900 - val_loss: 0.1502 - val_accuracy: 0.9750\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1578 - accuracy: 0.9925 - val_loss: 0.1388 - val_accuracy: 0.9750\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9937 - val_loss: 0.1284 - val_accuracy: 0.9800\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9950 - val_loss: 0.1195 - val_accuracy: 0.9850\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9937 - val_loss: 0.1126 - val_accuracy: 0.9750\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9912 - val_loss: 0.1047 - val_accuracy: 0.9850\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9937 - val_loss: 0.0978 - val_accuracy: 0.9850\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9925 - val_loss: 0.0923 - val_accuracy: 0.9850\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9925 - val_loss: 0.0877 - val_accuracy: 0.9900\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0943 - accuracy: 0.9937 - val_loss: 0.0819 - val_accuracy: 0.9850\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9925 - val_loss: 0.0780 - val_accuracy: 0.9900\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9937 - val_loss: 0.0751 - val_accuracy: 0.9900\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9937 - val_loss: 0.0708 - val_accuracy: 0.9850\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9937 - val_loss: 0.0679 - val_accuracy: 0.9900\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9937 - val_loss: 0.0649 - val_accuracy: 0.9900\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9937 - val_loss: 0.0623 - val_accuracy: 0.9900\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9937 - val_loss: 0.0600 - val_accuracy: 0.9900\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9937 - val_loss: 0.0575 - val_accuracy: 0.9900\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0638 - accuracy: 0.9937 - val_loss: 0.0553 - val_accuracy: 0.9900\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9937 - val_loss: 0.0535 - val_accuracy: 0.9900\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9937 - val_loss: 0.0519 - val_accuracy: 0.9900\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9950 - val_loss: 0.0500 - val_accuracy: 0.9900\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9937 - val_loss: 0.0487 - val_accuracy: 0.9900\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9925 - val_loss: 0.0472 - val_accuracy: 0.9900\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9937 - val_loss: 0.0462 - val_accuracy: 0.9900\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9950 - val_loss: 0.0449 - val_accuracy: 0.9900\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9937 - val_loss: 0.0436 - val_accuracy: 0.9900\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9937 - val_loss: 0.0426 - val_accuracy: 0.9950\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9950 - val_loss: 0.0417 - val_accuracy: 0.9900\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9950 - val_loss: 0.0413 - val_accuracy: 0.9900\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9937 - val_loss: 0.0398 - val_accuracy: 0.9900\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9937 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9950 - val_loss: 0.0384 - val_accuracy: 0.9900\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9937 - val_loss: 0.0373 - val_accuracy: 0.9950\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9950 - val_loss: 0.0366 - val_accuracy: 0.9950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8b66c0128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3FHYjKuKPAq",
        "colab_type": "code",
        "outputId": "ddbd3b4e-242a-4af3-dd4a-2462a29e4f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "def display_trained_model_line():\n",
        "  W, b = layer.get_weights()\n",
        "  slope = np.linspace(0, 1)\n",
        "  Y = -((W[0] * slope + b) / W[1])\n",
        "  plt.title('Trained model separating line')\n",
        "  plt.plot(slope, Y, color='green')\n",
        "  plt.show()\n",
        "\n",
        "display_random_data(test_data, test_labels, w, b)\n",
        "display_trained_model_line()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZMFXw_-2VYV",
        "colab_type": "text"
      },
      "source": [
        "## **Finetuning a pretrained model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooO1agqkGfaN",
        "colab_type": "text"
      },
      "source": [
        "The snippets of code below are from hw4 and show the main steps of fine-tuning. \n",
        "For finetuning we can unfreeze some layers to make them trainable. It is preferable to choose a layer that are at the top rather than the ones at the bottom. This will be easier to increase accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOMChPJQyHat",
        "colab_type": "text"
      },
      "source": [
        "The code below creates a pre-trained model with the Xception convolutional base."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSNzpDtovpk2",
        "colab_type": "code",
        "outputId": "36f956e3-c63c-4c47-b655-29191226db98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.applications.xception import Xception\n",
        "\n",
        "conv_base = Xception(\n",
        "    weights='imagenet', \n",
        "    include_top=False, \n",
        "    input_shape=(150, 150, 3))\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 36, 36, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 18, 18, 256)  32768       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 18, 18, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 9, 9, 728)    186368      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 9, 9, 728)    2912        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 5, 5, 1024)   745472      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 5, 5, 1024)   4096        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7V-V7IkzQvS",
        "colab_type": "text"
      },
      "source": [
        "Concatenates the of convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS3uF6KXvql7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTtKwWrkvyQS",
        "colab_type": "code",
        "outputId": "9a3e6036-efa0-4fea-b82d-3441765e691e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Model)             (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 33,969,193\n",
            "Trainable params: 13,107,713\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyG1uPIjx0vc",
        "colab_type": "text"
      },
      "source": [
        "The snippet of code below unfreezes the layer block10_sepconv1 and it also shows some of the trainable layers after a certain level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ced_D2YXer_g",
        "colab_type": "code",
        "outputId": "ec43c7a6-bf82-4089-bc72-f0362af4a0f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        }
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "\n",
        "print(\"TRAINABLE LAYERS:\\n\")\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block10_sepconv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "    print(layer.name)\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINABLE LAYERS:\n",
            "\n",
            "block10_sepconv1\n",
            "block10_sepconv1_bn\n",
            "block10_sepconv2_act\n",
            "block10_sepconv2\n",
            "block10_sepconv2_bn\n",
            "block10_sepconv3_act\n",
            "block10_sepconv3\n",
            "block10_sepconv3_bn\n",
            "add_9\n",
            "block11_sepconv1_act\n",
            "block11_sepconv1\n",
            "block11_sepconv1_bn\n",
            "block11_sepconv2_act\n",
            "block11_sepconv2\n",
            "block11_sepconv2_bn\n",
            "block11_sepconv3_act\n",
            "block11_sepconv3\n",
            "block11_sepconv3_bn\n",
            "add_10\n",
            "block12_sepconv1_act\n",
            "block12_sepconv1\n",
            "block12_sepconv1_bn\n",
            "block12_sepconv2_act\n",
            "block12_sepconv2\n",
            "block12_sepconv2_bn\n",
            "block12_sepconv3_act\n",
            "block12_sepconv3\n",
            "block12_sepconv3_bn\n",
            "add_11\n",
            "block13_sepconv1_act\n",
            "block13_sepconv1\n",
            "block13_sepconv1_bn\n",
            "block13_sepconv2_act\n",
            "block13_sepconv2\n",
            "block13_sepconv2_bn\n",
            "conv2d_4\n",
            "block13_pool\n",
            "batch_normalization_4\n",
            "add_12\n",
            "block14_sepconv1\n",
            "block14_sepconv1_bn\n",
            "block14_sepconv1_act\n",
            "block14_sepconv2\n",
            "block14_sepconv2_bn\n",
            "block14_sepconv2_act\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJXgN02MG6Bc",
        "colab_type": "text"
      },
      "source": [
        "## **Conclusion:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1zO2JhEG-zN",
        "colab_type": "text"
      },
      "source": [
        "Throughout this course, I have been able to learn some really interesting topics in the area of machine learning. Now that the class is over I still see myself learning more about this field and its concepts."
      ]
    }
  ]
}