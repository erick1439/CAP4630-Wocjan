{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP05yK8mHzvDOMpiqlh2+Hb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erick1439/CAP4630-Wocjan/blob/master/HW_5/HW_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HADODPXyGhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mpl_toolkits import mplot3d\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI_dNAtCg2yW",
        "colab_type": "text"
      },
      "source": [
        "# **Description:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKCW6aAEg0Cy",
        "colab_type": "text"
      },
      "source": [
        "Summarize and describe the different concepts/methods/algorithms that you have learned in this course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAGJqsZVg-Hf",
        "colab_type": "text"
      },
      "source": [
        "# **Summary:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U91XjtrxiB3_",
        "colab_type": "text"
      },
      "source": [
        "## **General Concepts:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i1L3iaYEkYY",
        "colab_type": "text"
      },
      "source": [
        "### ***Artificial Intellegence:*** \n",
        "\n",
        "I learned that AI is an umbrella term used to represents a branch of computer science dealing with the simulation of intelligent behavior in computers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ7waO8SFyQT",
        "colab_type": "text"
      },
      "source": [
        "### ***Symobolic AI:***\n",
        "This is a term to used to respresent the collection of all methods in AI research that are based on high level representations of problems. This term is also know as \"good old-fashioned Artificial Intelligence\" or GOFAI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzQr89XvHpkd",
        "colab_type": "text"
      },
      "source": [
        "### ***Machine Learning:***\n",
        "\n",
        "I learned that this term is a subset of AI which is used to represent the field of study that gives computers the ability to learn without being explicitly programmed. This means that Machine Learning is the process of trainning a model to make useful predictions using a data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzdoefxBKNVF",
        "colab_type": "text"
      },
      "source": [
        "#### ***Supervised Learning:***\n",
        "I learned that this is a paradigm from ML where a model will receive a label and training data. In the learing section, the model will do calculations to find patterns and relationships between the data and labels so when the model sees new data it can make close predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm7uNqx_N1X3",
        "colab_type": "text"
      },
      "source": [
        "#### ***Unsupervised Learning:***\n",
        "In this type of learning the model will have only unlabeled data. This means that the model will have no hints on how to categorize data. This type of learning is more useful if we want to classify new data in already existing clusters of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTgRBPUlPPJl",
        "colab_type": "text"
      },
      "source": [
        "#### ***Reinforcement Learning:***\n",
        "I learned that on this type of learning you do not collect example with label. Instead we have an agent that will learn how to interact with an enviroment through trial and error using feedback from previous actions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiCwXpeaUttA",
        "colab_type": "text"
      },
      "source": [
        "### **Deep Learning:**\n",
        "Deep learning is a set of machine learning based on artificial neural networks. The learning can be supervised or unsupervised."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I4D3D3tVTng",
        "colab_type": "text"
      },
      "source": [
        "## **Basic Concepts:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LahJFUFFVcva",
        "colab_type": "text"
      },
      "source": [
        "### **Linear Regression:**\n",
        "Linear regression is a formula that attempts to model a relationship between variables. In the most basic example it will create a line where it maps a dependent variable to an independet variable. The linear regresion equation could be written as : $\\hat y = mx + b$, but for this course the formula $\\hat y = b + \\sum_{j = 1}^n W_j X_j$ makes a better representation since it represents the linear regresion with multiple features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhWQWdbV9sW-",
        "colab_type": "code",
        "outputId": "1c7f052e-627e-4102-b3a1-64f5f80baf70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Display data points on the graph\n",
        "rng = np.random.RandomState(1)\n",
        "x = 10 * rng.rand(50)\n",
        "y = 2 * x - 5 + rng.randn(50)\n",
        "plt.scatter(x, y);\n",
        "\n",
        "# Generates the linear regression line\n",
        "model = LinearRegression(fit_intercept=True)\n",
        "model.fit(x[:, np.newaxis], y)\n",
        "xfit = np.linspace(0, 10, 1000)\n",
        "yfit = model.predict(xfit[:, np.newaxis])\n",
        "\n",
        "# Displays the line on the graph\n",
        "plt.scatter(x, y)\n",
        "plt.plot(xfit, yfit);"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU6FnaYTZno3",
        "colab_type": "text"
      },
      "source": [
        "### **Mean Square Error Loss:**\n",
        "Loss defines the penalty for a bad prediction from a single weight. Mean square error refers to the average squared loss per example over the whole dataset. The MSE can be represented as: $ \\frac{1}{m} \\sum_{i = 1}^m (y^i - \\hat y^i)^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKGHeeJ7JdK6",
        "colab_type": "text"
      },
      "source": [
        "### Binary crossentropy:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFGz4IfEJq9W",
        "colab_type": "text"
      },
      "source": [
        "Binary crossentropy is another type of loss function used primarly with logistic regression. Binary crossentropy will measure how far away from a true value a prediction will be measuring the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJAUaTSwJkEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_cross_entropy_loss(a, label):\n",
        "    return (-label * np.log(a)) - ((1 - label) * np.log(1 - a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvrNVJMRYdhT",
        "colab_type": "text"
      },
      "source": [
        "### **Logistic Regression:**\n",
        "This is a supervised learning algorithm that allow us to predict if something is true or false. Instead of having predictions for continious values like in linear regression, we will us logistic regression to classify data into two categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGVzTt-DYoNZ",
        "colab_type": "text"
      },
      "source": [
        "### **Gradients:**\n",
        "Gradients are vectors containing derivaties of functions with respect to all of its variables. One of the uses of gradients is to find the steepst ascent for a function at a given point.\n",
        "\n",
        "Below is an expalme of the gradient descent ot the function cos(x) + sin(y) at the point $(0, - \\frac{\\pi}{2})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFTFXWD8xU7P",
        "colab_type": "code",
        "outputId": "57fe27ec-3f64-41ad-c5aa-b4974cbdfa2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "def f3(x, y):\n",
        "  return np.cos(x) + np.sin(y)\n",
        "\n",
        "x = np.linspace(-4, 4, 30)\n",
        "y = np.linspace(-4, 4, 30)\n",
        "\n",
        "X, Y = np.meshgrid(x, y)\n",
        "Z = f3(X, Y)\n",
        "\n",
        "plt.contourf(X, Y, Z, 20, cmap='RdGy')\n",
        "plt.colorbar()\n",
        "plt.plot(0, -np.pi / 2, 'o', c='green')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EolPuNIUZ2It",
        "colab_type": "text"
      },
      "source": [
        "### **Gradient Descent:**\n",
        "This a technique we use to minimized the error loss of a model by adjusting its weights. This optimization technique works by iteratively moving in the direction of the functions's steepest descent. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U4cxeGGZ6Ju",
        "colab_type": "text"
      },
      "source": [
        "### **Stochastic/ Mini Batch Gradient Descent:**\n",
        "Stochastic and Mini batch are two modifications of gradiant descent. Running the gradieant descent algorithm can be very costly because of the many math computations the algorith will have to compute with big sets of data. To prevent this we can use Stochastic and mini batch gradient descent. Sotachistic will randomly select a element from the training set at each step. In the other side, the mini batch will use a small collection of randomly choosed elements from the training set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNDvi9Hq1deI",
        "colab_type": "text"
      },
      "source": [
        "## **Building a Model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJshcTwlLsp2",
        "colab_type": "text"
      },
      "source": [
        "Keras allows us to build neural networks in a condese way. In the lines below we are creating a sequential model which will organize out the layer in stack looking fashion. After that, we are inserting a dense layer to the model that will use a sigmod activation. The sigmoid argument will make sure that our output is between the interval 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMhWfeEoLy93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "f6ab308d-4c69-4aa8-f7f0-f7f4d7d6e0ed"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "# Creates the model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Adds dense layer to the model\n",
        "layer = tf.keras.layers.Dense(1, activation='sigmoid', input_shape=(2, ))\n",
        "model.add(layer)\n",
        "\n",
        "# Summary\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYMcWMcg1CjU",
        "colab_type": "text"
      },
      "source": [
        "### **Types of layers:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73cVJ8MU1Npi",
        "colab_type": "text"
      },
      "source": [
        "There are different types of layers that keras offer. The dense layer used above is just one of the many. Below are just some layers we have come across:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqtBkvG71hBD",
        "colab_type": "text"
      },
      "source": [
        "#### **Dense:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31qi8VCT15d4",
        "colab_type": "text"
      },
      "source": [
        "Dense is one of the most basic types of layers. This layer uses the gradiant descent technique to adjust the features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaaXaKKC1wfC",
        "colab_type": "text"
      },
      "source": [
        "#### **Flatten:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K3nwHr_Boa1",
        "colab_type": "text"
      },
      "source": [
        "The flatten layer can take an input of multiple dimesion and flatten that into a 1d array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1yO0buy1k4W",
        "colab_type": "text"
      },
      "source": [
        "#### **Conv2D:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itDcd4WX4bAc",
        "colab_type": "text"
      },
      "source": [
        "This layer works by reciving an input matrix and a kernel. Then this kernel will be used to multiply the input matrix on a specific region of the input matrix and then add its products. This process will continue until the all the input matrix positions have been processed. The code below is the example from hw4 that computes the conv2d on squares matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJyH_SlS1rOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "361f5976-67ec-4f13-dc31-6547059ca958"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def conv2d(input_mat, kernel_mat):\n",
        "    # Special cases in order to avoid errors on the computation.\n",
        "\n",
        "    if kernel_mat.shape[0] != kernel_mat.shape[1]:\n",
        "      return \"Kernel matrix is not square\"\n",
        "    \n",
        "    if input_mat.shape[0] != input_mat.shape[1]:\n",
        "      return \"Input matrix is not square\"\n",
        "\n",
        "    if kernel_mat.shape[0] > input_mat.shape[0]:\n",
        "      return \"Kernel size is greater than the input size\"\n",
        "\n",
        "    # Statements that calculate the new length of the result matrix.\n",
        "    result_mat = np.zeros((input_mat.shape[0] - kernel_mat.shape[0] + 1, input_mat.shape[0] - kernel_mat.shape[0] + 1))\n",
        "\n",
        "    # Loops that calculate the convolution computations\n",
        "    for col in range(result_mat.shape[0]):\n",
        "        for row in range(result_mat.shape[1]):\n",
        "          x_bound = row + kernel_mat.shape[0];\n",
        "          y_bound = col + kernel_mat.shape[0]\n",
        "          temp_mat = np.multiply(input_mat[col:y_bound, row:x_bound], kernel_mat)\n",
        "          result_mat[col][row] = np.sum(temp_mat)\n",
        "\n",
        "    return result_mat\n",
        "\n",
        "\n",
        "# Test case : \n",
        "input_mat = np.array([[1, 2, 3],\n",
        "                      [1, 2, 3],\n",
        "                      [1, 2, 3]])\n",
        "\n",
        "kernel_mat = np.array([[1, 1],\n",
        "                       [1, 1]])\n",
        "\n",
        "print(conv2d(input_mat, kernel_mat), end=\"\\n\\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6. 10.]\n",
            " [ 6. 10.]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4SXgTIJ1rsc",
        "colab_type": "text"
      },
      "source": [
        "#### **MaxPooling2D:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWE6Qnsf8GH7",
        "colab_type": "text"
      },
      "source": [
        "This layer works get the max number from a region specified by a value passed as another parameter. This tehcnique will also stop when all the values of the input matrix have been processed. The example below is from hw4 that works only with only square matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_TP2S9E7S1Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b2ff31e7-d382-41dc-9c01-7f078479af37"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def maxpooling2d(input_mat, s):\n",
        "\n",
        "  # Special cases in order to avoid errors on the computation.\n",
        "  if input_mat.shape[0] != input_mat.shape[1]:\n",
        "    return \"Input Matrix is not square\"\n",
        "\n",
        "  if s <= 0:\n",
        "    return \"Make sure the value in s is valid\"\n",
        "\n",
        "  if s > input_mat.shape[0]:\n",
        "    return \"The value in s is largert the input size\"\n",
        "\n",
        "  # Statements that calculate the new length of the result matrix.\n",
        "  result_mat = np.zeros((input_mat.shape[0] // s, input_mat.shape[0] // s))\n",
        "\n",
        "  # Perform the max pooling operation\n",
        "  for col in range(result_mat.shape[0]):\n",
        "    for row in range(result_mat.shape[0]):\n",
        "      x_bound = row * s\n",
        "      y_bound = col * s\n",
        "      result_mat[col][row] = np.amax(input_mat[y_bound:y_bound + s, x_bound:x_bound + s])\n",
        "\n",
        "  return result_mat\n",
        "\n",
        "\n",
        "# Test case:\n",
        "input_mat = np.array([[1, 2, 3, 4],\n",
        "                      [5, 6, 7, 8],\n",
        "                      [9, 10, 11, 12],\n",
        "                      [13, 14, 15, 16]])\n",
        "\n",
        "print(maxpooling2d(input_mat, 2), end=\"\\n\\n\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 6.  8.]\n",
            " [14. 16.]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzavZlaR16fl",
        "colab_type": "text"
      },
      "source": [
        "## **Comping a Model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74l21jehuKGZ",
        "colab_type": "text"
      },
      "source": [
        "The model above can be compiled with the line below. The optimizer parameter is in charge to set how the data is going to be updated at each iteration. The loss parameter is in charge to set the algorithm that it will be used to calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s7GJnjj5d57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEJjpvSX2E06",
        "colab_type": "text"
      },
      "source": [
        "## **Training a Model:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcKcyHwR5KM4",
        "colab_type": "text"
      },
      "source": [
        "#### ***Overfitting:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjIt1n_9Z6kE",
        "colab_type": "text"
      },
      "source": [
        "Overfitting is a pitfall where a model will train training-data too well. This is bad because because it will cause big loss in unseen data. This usually happens when the model learns the noise and the detail rules for the training. One of the ways to avoid this problem is by using more general rules to train the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGI6zDlQ5bd-",
        "colab_type": "text"
      },
      "source": [
        "#### ***Underfitting:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aes4vLLHeFSq",
        "colab_type": "text"
      },
      "source": [
        "Underfitting refers to a model that can not train data or generalize new data. To fix this, we can change the learning rate or increase the amount of the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU_1eR8nLG5F",
        "colab_type": "text"
      },
      "source": [
        "#### **Training model Example:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zDVQ6uLLdcC",
        "colab_type": "text"
      },
      "source": [
        "The example below is part of hw3 that implements logistic regresion with two features and training data from the get_random() mehtod."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlurMwdIJm6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "edccd481-f210-461f-94a5-af844544fc7f"
      },
      "source": [
        "def get_random_data(w, b, mu, sigma, m):\n",
        "  # Generates array with ones and zeros.\n",
        "  labels = np.random.choice([0, 1], size=(m,1))\n",
        "  \n",
        "  # Generates uniformly random data.\n",
        "  X_1 = np.random.uniform(0, 1, size=(m, 1))\n",
        "\n",
        "  # Generates random data with mean distribution of mu, and sd of sigma.\n",
        "  N = np.random.normal(mu, sigma, size=(m, 1))\n",
        "\n",
        "  # Sets the second feature\n",
        "  X_2 = w * X_1 + b + (-1)**labels * N\n",
        "\n",
        "  # Concatenates the features X_1 & X_2 to produce the array with a shape of (m, 2).\n",
        "  data = np.concatenate((X_1, X_2), axis=1)\n",
        "\n",
        "  return data, labels\n",
        "\n",
        "def split_data(data, labels):\n",
        "  # Splits the data with a 80:20 ratio\n",
        "  train_data = data[:(int)(m * 0.8)]\n",
        "  test_data = data[(int)(m * 0.8):]\n",
        "  train_labels = labels[:(int)(m * 0.8)]\n",
        "  test_labels = labels[(int)(m * 0.8):]\n",
        "\n",
        "  return train_data, test_data, train_labels, test_labels\n",
        "\n",
        "def display_random_data (data, labels, w, b):\n",
        "  # Display data points \n",
        "  pt = labels.flatten()\n",
        "  temp1 = data[pt == 0,:]\n",
        "  temp2 = data[pt == 1,:]\n",
        "  plt.scatter(temp1[:,0], temp1[:,1], c='blue', label='X_1')\n",
        "  plt.scatter(temp2[:,0], temp2[:,1], c='red', label='X_2')\n",
        "\n",
        "  # Displays line that splits the data\n",
        "  slope = np.linspace(0, 1)\n",
        "  y = w * slope + b\n",
        "  plt.plot(slope, y, 'black')\n",
        "\n",
        "  # Labels the graph\n",
        "  plt.title('Data Distribution')\n",
        "  plt.xlabel('$Y$')\n",
        "  plt.ylabel('$X$')\n",
        "\n",
        "\n",
        "w = 2\n",
        "b = 7\n",
        "mu = 4\n",
        "sigma = 1.5\n",
        "m = 1000\n",
        "\n",
        "data, labels = get_random_data(w, b, mu, sigma, m)\n",
        "train_data, test_data, train_labels, test_labels = split_data(data, labels)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 40\n",
        "\n",
        "# Creates the model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Adds dense layer to the model\n",
        "layer = tf.keras.layers.Dense(1, activation='sigmoid', input_shape=(2, ))\n",
        "model.add(layer)\n",
        "\n",
        "# Compiles the model\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Trains the model\n",
        "model.fit(train_data, train_labels, epochs=epochs, batch_size=batch_size, validation_data=(test_data, test_labels))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 4.3784 - accuracy: 0.4975 - val_loss: 4.0290 - val_accuracy: 0.4350\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 3.0023 - accuracy: 0.4775 - val_loss: 2.6504 - val_accuracy: 0.3950\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1.8742 - accuracy: 0.3688 - val_loss: 1.4843 - val_accuracy: 0.1800\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1.1342 - accuracy: 0.0787 - val_loss: 0.9122 - val_accuracy: 0.2350\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.8521 - accuracy: 0.4338 - val_loss: 0.7465 - val_accuracy: 0.5550\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.4975 - val_loss: 0.6616 - val_accuracy: 0.5550\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.4975 - val_loss: 0.5979 - val_accuracy: 0.5550\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.5000 - val_loss: 0.5452 - val_accuracy: 0.5650\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.5350 - val_loss: 0.5095 - val_accuracy: 0.6800\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.6363 - val_loss: 0.4512 - val_accuracy: 0.7150\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7375 - val_loss: 0.4102 - val_accuracy: 0.8200\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8313 - val_loss: 0.3704 - val_accuracy: 0.8450\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3804 - accuracy: 0.8913 - val_loss: 0.3384 - val_accuracy: 0.9250\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.9337 - val_loss: 0.3084 - val_accuracy: 0.9450\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.9600 - val_loss: 0.2797 - val_accuracy: 0.9400\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.9638 - val_loss: 0.2571 - val_accuracy: 0.9500\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.9638 - val_loss: 0.2368 - val_accuracy: 0.9600\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.9762 - val_loss: 0.2183 - val_accuracy: 0.9700\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.9762 - val_loss: 0.2004 - val_accuracy: 0.9700\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.2046 - accuracy: 0.9812 - val_loss: 0.1853 - val_accuracy: 0.9800\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1885 - accuracy: 0.9837 - val_loss: 0.1704 - val_accuracy: 0.9700\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1751 - accuracy: 0.9850 - val_loss: 0.1599 - val_accuracy: 0.9850\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9875 - val_loss: 0.1475 - val_accuracy: 0.9800\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1502 - accuracy: 0.9875 - val_loss: 0.1377 - val_accuracy: 0.9850\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1403 - accuracy: 0.9862 - val_loss: 0.1284 - val_accuracy: 0.9850\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9887 - val_loss: 0.1203 - val_accuracy: 0.9850\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9875 - val_loss: 0.1132 - val_accuracy: 0.9850\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9875 - val_loss: 0.1070 - val_accuracy: 0.9850\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9887 - val_loss: 0.1011 - val_accuracy: 0.9850\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.1020 - accuracy: 0.9900 - val_loss: 0.0952 - val_accuracy: 0.9850\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0957 - accuracy: 0.9887 - val_loss: 0.0901 - val_accuracy: 0.9850\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9912 - val_loss: 0.0852 - val_accuracy: 0.9900\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9900 - val_loss: 0.0809 - val_accuracy: 0.9850\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9887 - val_loss: 0.0774 - val_accuracy: 0.9900\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9912 - val_loss: 0.0739 - val_accuracy: 0.9900\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9900 - val_loss: 0.0707 - val_accuracy: 0.9900\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9900 - val_loss: 0.0680 - val_accuracy: 0.9900\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9900 - val_loss: 0.0655 - val_accuracy: 0.9900\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9887 - val_loss: 0.0631 - val_accuracy: 0.9900\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9887 - val_loss: 0.0607 - val_accuracy: 0.9900\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9887 - val_loss: 0.0588 - val_accuracy: 0.9900\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9900 - val_loss: 0.0568 - val_accuracy: 0.9900\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9900 - val_loss: 0.0557 - val_accuracy: 0.9900\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9925 - val_loss: 0.0534 - val_accuracy: 0.9900\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9912 - val_loss: 0.0513 - val_accuracy: 0.9950\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9937 - val_loss: 0.0505 - val_accuracy: 0.9900\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0506 - accuracy: 0.9900 - val_loss: 0.0491 - val_accuracy: 0.9950\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9925 - val_loss: 0.0473 - val_accuracy: 0.9950\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0476 - accuracy: 0.9912 - val_loss: 0.0459 - val_accuracy: 0.9950\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9937 - val_loss: 0.0447 - val_accuracy: 0.9950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f015ffbf080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3FHYjKuKPAq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "722e9bfe-93d3-45b1-ab14-862c647e20e0"
      },
      "source": [
        "def display_trained_model_line():\n",
        "  W, b = layer.get_weights()\n",
        "  slope = np.linspace(0, 1)\n",
        "  Y = -((W[0] * slope + b) / W[1])\n",
        "  plt.title('Trained model separating line')\n",
        "  plt.plot(slope, Y, color='green')\n",
        "  plt.show()\n",
        "\n",
        "display_random_data(test_data, test_labels, w, b)\n",
        "display_trained_model_line()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZMFXw_-2VYV",
        "colab_type": "text"
      },
      "source": [
        "## **Finetuning a pretrained model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooO1agqkGfaN",
        "colab_type": "text"
      },
      "source": [
        "The snippets of code below are from hw4 and show the main steps of fine tuning. \n",
        "For finetuning we can unfreeze some layers to make them trainable. It is preferable to choose layer that are at the top rather than the ones at the bottom. This it will be easier to increase the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOMChPJQyHat",
        "colab_type": "text"
      },
      "source": [
        "The code below creates a pretrainded model with the Xception convolutional base."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSNzpDtovpk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f76144ee-1d45-486c-a202-cf8826d59aeb"
      },
      "source": [
        "from keras.applications.xception import Xception\n",
        "\n",
        "conv_base = Xception(\n",
        "    weights='imagenet', \n",
        "    include_top=False, \n",
        "    input_shape=(150, 150, 3))\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 74, 74, 32)   128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 74, 74, 32)   0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 72, 72, 64)   18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 72, 72, 64)   256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 72, 72, 64)   0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 72, 72, 128)  8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 72, 72, 128)  0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 72, 72, 128)  17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 72, 72, 128)  512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 36, 36, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 36, 36, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 36, 36, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 36, 36, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 36, 36, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 36, 36, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 36, 36, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 36, 36, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 36, 36, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 18, 18, 256)  32768       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 18, 18, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 18, 18, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 18, 18, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 18, 18, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 18, 18, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 18, 18, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 18, 18, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 18, 18, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 9, 9, 728)    186368      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 9, 9, 728)    0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 9, 9, 728)    2912        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 9, 9, 728)    0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 9, 9, 728)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 9, 9, 728)    0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 9, 9, 728)    0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 9, 9, 728)    0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 9, 9, 728)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 9, 9, 728)    0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 9, 9, 728)    0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 9, 9, 728)    0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 9, 9, 728)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 9, 9, 728)    0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 9, 9, 728)    0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 9, 9, 728)    0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 9, 9, 728)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 9, 9, 728)    0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 9, 9, 728)    0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 9, 9, 728)    0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 9, 9, 728)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 9, 9, 728)    0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 9, 9, 728)    0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 9, 9, 728)    536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 9, 9, 728)    2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 9, 9, 728)    0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 9, 9, 728)    0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 9, 9, 728)    0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 9, 9, 728)    0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 9, 9, 728)    0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 9, 9, 728)    0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 9, 9, 728)    0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 9, 9, 728)    0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 9, 9, 728)    0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 9, 9, 728)    536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 9, 9, 728)    2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 9, 9, 728)    0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 9, 9, 728)    0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 9, 9, 728)    536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 9, 9, 728)    2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 9, 9, 728)    0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 9, 9, 1024)   752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 9, 9, 1024)   4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 5, 5, 1024)   745472      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 5, 5, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 5, 5, 1024)   4096        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 5, 5, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 5, 5, 1536)   1582080     add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 5, 5, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 5, 5, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 5, 5, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 5, 5, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 5, 5, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7V-V7IkzQvS",
        "colab_type": "text"
      },
      "source": [
        "Concanates the of convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS3uF6KXvql7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTtKwWrkvyQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "d3a86215-8a24-4d1a-eca3-852bf382ef5a"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "xception (Model)             (None, 5, 5, 2048)        20861480  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 33,969,193\n",
            "Trainable params: 13,107,713\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyG1uPIjx0vc",
        "colab_type": "text"
      },
      "source": [
        "The snippet of code below unfreezes the layer block10_sepconv1 and it also shows some of the trainable layer after a certain level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ced_D2YXer_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "outputId": "0013b81f-390c-4e52-dd30-da7c2b6d4d9e"
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "\n",
        "print(\"TRAINABLE LAYERS:\\n\")\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block10_sepconv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "    print(layer.name)\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINABLE LAYERS:\n",
            "\n",
            "block10_sepconv1\n",
            "block10_sepconv1_bn\n",
            "block10_sepconv2_act\n",
            "block10_sepconv2\n",
            "block10_sepconv2_bn\n",
            "block10_sepconv3_act\n",
            "block10_sepconv3\n",
            "block10_sepconv3_bn\n",
            "add_9\n",
            "block11_sepconv1_act\n",
            "block11_sepconv1\n",
            "block11_sepconv1_bn\n",
            "block11_sepconv2_act\n",
            "block11_sepconv2\n",
            "block11_sepconv2_bn\n",
            "block11_sepconv3_act\n",
            "block11_sepconv3\n",
            "block11_sepconv3_bn\n",
            "add_10\n",
            "block12_sepconv1_act\n",
            "block12_sepconv1\n",
            "block12_sepconv1_bn\n",
            "block12_sepconv2_act\n",
            "block12_sepconv2\n",
            "block12_sepconv2_bn\n",
            "block12_sepconv3_act\n",
            "block12_sepconv3\n",
            "block12_sepconv3_bn\n",
            "add_11\n",
            "block13_sepconv1_act\n",
            "block13_sepconv1\n",
            "block13_sepconv1_bn\n",
            "block13_sepconv2_act\n",
            "block13_sepconv2\n",
            "block13_sepconv2_bn\n",
            "conv2d_4\n",
            "block13_pool\n",
            "batch_normalization_4\n",
            "add_12\n",
            "block14_sepconv1\n",
            "block14_sepconv1_bn\n",
            "block14_sepconv1_act\n",
            "block14_sepconv2\n",
            "block14_sepconv2_bn\n",
            "block14_sepconv2_act\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJXgN02MG6Bc",
        "colab_type": "text"
      },
      "source": [
        "## **Conclusion:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1zO2JhEG-zN",
        "colab_type": "text"
      },
      "source": [
        "Throught out this course I have been able to learn some really intersting topics on the area of machine learning. Now that the class is over I still see myself learning more about this field and its concepts."
      ]
    }
  ]
}